{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Centralized_case_FL_proposta_algoritmo_compressao.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JUeu2bFxpN85"
      ],
      "authorship_tag": "ABX9TyPoM6LbIhULm37JFoqYEjf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NRiccieri/HIAAC_Project_Group3/blob/main/Centralized_case_FL_proposta_algoritmo_compressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FL Compression Algorithm**\n",
        "\n",
        "In this notebook, we train a DNN on a single machine containing all the datasets for training.\n",
        "\n",
        "This will be used as reference for experiments in training the same DNN model under FL environment. \n"
      ],
      "metadata": {
        "id": "JkzJr8-ovoO7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tQ3MhPtrvgrh"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create gdrive folder inside content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbdaqcm2Ydwt",
        "outputId": "bbb25676-8875-4151-c88e-6d2b16fe6a7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dataset to google colab from gdrive\n",
        "!cp /content/gdrive/MyDrive/kaggle_datasets/archive.zip  /content/archive.zip \n",
        "\n",
        "#unzipping \n",
        "!unzip archive.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPZunpY7Ysbo",
        "outputId": "c984f19d-7d2a-4616-d80c-a9d0f901b09d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "pAojsMm0lEul"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "2rl9yavblhi2",
        "outputId": "98a2e6c1-8ac1-4e98-e733-ce31e1789f77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
              "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
              "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
              "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
              "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
              "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
              "\n",
              "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
              "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
              "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
              "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
              "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
              "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
              "\n",
              "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-kurtosis()  \\\n",
              "0         -0.923527         -0.934724  ...                        -0.710304   \n",
              "1         -0.957686         -0.943068  ...                        -0.861499   \n",
              "2         -0.977469         -0.938692  ...                        -0.760104   \n",
              "3         -0.989302         -0.938692  ...                        -0.482845   \n",
              "4         -0.990441         -0.942469  ...                        -0.699205   \n",
              "\n",
              "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
              "0                    -0.112754                              0.030400   \n",
              "1                     0.053477                             -0.007435   \n",
              "2                    -0.118559                              0.177899   \n",
              "3                    -0.036788                             -0.012892   \n",
              "4                     0.123320                              0.122542   \n",
              "\n",
              "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
              "0                         -0.464761                             -0.018446   \n",
              "1                         -0.732626                              0.703511   \n",
              "2                          0.100699                              0.808529   \n",
              "3                          0.640011                             -0.485366   \n",
              "4                          0.693578                             -0.615971   \n",
              "\n",
              "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  subject  \\\n",
              "0             -0.841247              0.179941             -0.058627        1   \n",
              "1             -0.844788              0.180289             -0.054317        1   \n",
              "2             -0.848933              0.180637             -0.049118        1   \n",
              "3             -0.848649              0.181935             -0.047663        1   \n",
              "4             -0.847865              0.185151             -0.043892        1   \n",
              "\n",
              "   Activity  \n",
              "0  STANDING  \n",
              "1  STANDING  \n",
              "2  STANDING  \n",
              "3  STANDING  \n",
              "4  STANDING  \n",
              "\n",
              "[5 rows x 563 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba9d8e66-a046-4651-9e96-7720888d89c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.288585</td>\n",
              "      <td>-0.020294</td>\n",
              "      <td>-0.132905</td>\n",
              "      <td>-0.995279</td>\n",
              "      <td>-0.983111</td>\n",
              "      <td>-0.913526</td>\n",
              "      <td>-0.995112</td>\n",
              "      <td>-0.983185</td>\n",
              "      <td>-0.923527</td>\n",
              "      <td>-0.934724</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.710304</td>\n",
              "      <td>-0.112754</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>-0.464761</td>\n",
              "      <td>-0.018446</td>\n",
              "      <td>-0.841247</td>\n",
              "      <td>0.179941</td>\n",
              "      <td>-0.058627</td>\n",
              "      <td>1</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.278419</td>\n",
              "      <td>-0.016411</td>\n",
              "      <td>-0.123520</td>\n",
              "      <td>-0.998245</td>\n",
              "      <td>-0.975300</td>\n",
              "      <td>-0.960322</td>\n",
              "      <td>-0.998807</td>\n",
              "      <td>-0.974914</td>\n",
              "      <td>-0.957686</td>\n",
              "      <td>-0.943068</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.861499</td>\n",
              "      <td>0.053477</td>\n",
              "      <td>-0.007435</td>\n",
              "      <td>-0.732626</td>\n",
              "      <td>0.703511</td>\n",
              "      <td>-0.844788</td>\n",
              "      <td>0.180289</td>\n",
              "      <td>-0.054317</td>\n",
              "      <td>1</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.279653</td>\n",
              "      <td>-0.019467</td>\n",
              "      <td>-0.113462</td>\n",
              "      <td>-0.995380</td>\n",
              "      <td>-0.967187</td>\n",
              "      <td>-0.978944</td>\n",
              "      <td>-0.996520</td>\n",
              "      <td>-0.963668</td>\n",
              "      <td>-0.977469</td>\n",
              "      <td>-0.938692</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.760104</td>\n",
              "      <td>-0.118559</td>\n",
              "      <td>0.177899</td>\n",
              "      <td>0.100699</td>\n",
              "      <td>0.808529</td>\n",
              "      <td>-0.848933</td>\n",
              "      <td>0.180637</td>\n",
              "      <td>-0.049118</td>\n",
              "      <td>1</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.279174</td>\n",
              "      <td>-0.026201</td>\n",
              "      <td>-0.123283</td>\n",
              "      <td>-0.996091</td>\n",
              "      <td>-0.983403</td>\n",
              "      <td>-0.990675</td>\n",
              "      <td>-0.997099</td>\n",
              "      <td>-0.982750</td>\n",
              "      <td>-0.989302</td>\n",
              "      <td>-0.938692</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.482845</td>\n",
              "      <td>-0.036788</td>\n",
              "      <td>-0.012892</td>\n",
              "      <td>0.640011</td>\n",
              "      <td>-0.485366</td>\n",
              "      <td>-0.848649</td>\n",
              "      <td>0.181935</td>\n",
              "      <td>-0.047663</td>\n",
              "      <td>1</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.276629</td>\n",
              "      <td>-0.016570</td>\n",
              "      <td>-0.115362</td>\n",
              "      <td>-0.998139</td>\n",
              "      <td>-0.980817</td>\n",
              "      <td>-0.990482</td>\n",
              "      <td>-0.998321</td>\n",
              "      <td>-0.979672</td>\n",
              "      <td>-0.990441</td>\n",
              "      <td>-0.942469</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.699205</td>\n",
              "      <td>0.123320</td>\n",
              "      <td>0.122542</td>\n",
              "      <td>0.693578</td>\n",
              "      <td>-0.615971</td>\n",
              "      <td>-0.847865</td>\n",
              "      <td>0.185151</td>\n",
              "      <td>-0.043892</td>\n",
              "      <td>1</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 563 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba9d8e66-a046-4651-9e96-7720888d89c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba9d8e66-a046-4651-9e96-7720888d89c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba9d8e66-a046-4651-9e96-7720888d89c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scMZ7vYyln_D",
        "outputId": "96039b3b-ab86-47f4-d954-a2f65a41c4cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 563)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH0fOmnUlzrR",
        "outputId": "68cbb29e-c7d4-4e06-f5d9-08a9acb0e690"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tBodyAcc-mean()-X       0\n",
              "tBodyAcc-mean()-Y       0\n",
              "tBodyAcc-mean()-Z       0\n",
              "tBodyAcc-std()-X        0\n",
              "tBodyAcc-std()-Y        0\n",
              "                       ..\n",
              "angle(X,gravityMean)    0\n",
              "angle(Y,gravityMean)    0\n",
              "angle(Z,gravityMean)    0\n",
              "subject                 0\n",
              "Activity                0\n",
              "Length: 563, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Activity'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDg2pAnrl2lS",
        "outputId": "c86f3f4a-97d3-4c49-88f7-d7f7d4306cca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
              "       'WALKING_UPSTAIRS'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "axis=sns.countplot(x=\"Activity\",data=df_train)\n",
        "plt.xticks(x=df_train['Activity'],rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "ITIjjP-9l6Mh",
        "outputId": "68fa49f4-4168-42e3-c454-bb9de72fc7c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['subject'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nywHE-z1l-Tg",
        "outputId": "18a9df36-f307-4301-bbdb-c60838e00dc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  3,  5,  6,  7,  8, 11, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26,\n",
              "       27, 28, 29, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=pd.DataFrame(df_train.drop(['Activity','subject'],axis=1))\n",
        "y=df_train.Activity.values.astype(object)"
      ],
      "metadata": {
        "id": "0J5vV2FemNhd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape , y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtjgYhKXmPl9",
        "outputId": "498b8d63-b6e4-4a02-b1a8-dac52b83dd43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7352, 561), (7352,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.Activity.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8motQFYomQ_6",
        "outputId": "45e24c7b-ae9b-4106-c820-df8675866815"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    STANDING\n",
              "1    STANDING\n",
              "2    STANDING\n",
              "3    STANDING\n",
              "4    STANDING\n",
              "Name: Activity, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "wXLX3Ovzmwwt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder=preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "YUqw6NGRmzEC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.fit(y)\n",
        "y=encoder.transform(y)\n",
        "print(\"shape of y: \", y.shape)\n",
        "\n",
        "print(\"y[5]=\", y[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyOmsZ8Xm3vA",
        "outputId": "dae340ae-b120-47e2-b575-8e4f76f8de5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of y:  (7352,)\n",
            "y[5]= 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HiVxMsxnKfm",
        "outputId": "a049ed81-0027-464e-9c4a-c9dfbc3b8f48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
              "       'WALKING_UPSTAIRS'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature scaling**"
      ],
      "metadata": {
        "id": "Uh0cajfWnV0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler=StandardScaler()\n",
        "\n",
        "x=scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "rZEwrsginXhR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the dataset into training and validation sets**"
      ],
      "metadata": {
        "id": "SWSpc7TZnzLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=100)"
      ],
      "metadata": {
        "id": "6bQyfQ-tn3Br"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff5puY0-oAzr",
        "outputId": "72f65dc8-54df-4d2c-a4da-256d8f87a3cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6616, 561), (736, 561), (6616,), (736,))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MLP classification in Sklearn**"
      ],
      "metadata": {
        "id": "JUeu2bFxpN85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "Vzt3JkG1pRSw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(50, 50), random_state=1, max_iter=500)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXv-W7-1pWQp",
        "outputId": "9149c1aa-fb10-455f-942b-76ac6ca203a5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58.75421738624573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "4kopXc0tqzFh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82tXz4CQq8no",
        "outputId": "34b59e16-924f-414d-a713-39a99689f845"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9850543478260869"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MLP in Tensorflow**"
      ],
      "metadata": {
        "id": "O6In90iQAH2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Activation\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KLvH7xEcAKnA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    \n",
        "    # reshape 28 row * 28 column data to 28*28 rows\n",
        "    Flatten(input_shape=(561,), name=\"inputlayer\"),\n",
        "    \n",
        "    # dense layer 1\n",
        "    Dense(256, activation='sigmoid', name=\"firstlayer\"),  \n",
        "    \n",
        "    # dense layer 2\n",
        "    Dense(256, activation='sigmoid', name=\"secondlayer\"), \n",
        "\n",
        "    # dense layer 3\n",
        "    Dense(256, activation='sigmoid', name=\"thirdlayer\"), \n",
        "    \n",
        "    # output layer\n",
        "    Dense(6, activation='sigmoid', name=\"outputlayer\"),  \n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rocruLoRAdHY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "model.fit(x, y, epochs=120, \n",
        "          validation_split=0.15)\n",
        "\n",
        "end = time.time()\n",
        "print(\"training time = \", end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K5DHID-BJlI",
        "outputId": "c3d55c82-f45d-4ebc-ef53-c27205032664"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.7736 - accuracy: 0.2082 - val_loss: 1.7530 - val_accuracy: 0.1859\n",
            "Epoch 2/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7168 - accuracy: 0.2687 - val_loss: 1.6864 - val_accuracy: 0.3309\n",
            "Epoch 3/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.6353 - accuracy: 0.3631 - val_loss: 1.5919 - val_accuracy: 0.3345\n",
            "Epoch 4/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.5043 - accuracy: 0.4029 - val_loss: 1.4269 - val_accuracy: 0.3345\n",
            "Epoch 5/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.3463 - accuracy: 0.4271 - val_loss: 1.2862 - val_accuracy: 0.3382\n",
            "Epoch 6/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.2284 - accuracy: 0.4265 - val_loss: 1.1942 - val_accuracy: 0.3345\n",
            "Epoch 7/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.1623 - accuracy: 0.4375 - val_loss: 1.1468 - val_accuracy: 0.4814\n",
            "Epoch 8/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.1263 - accuracy: 0.4623 - val_loss: 1.1078 - val_accuracy: 0.5005\n",
            "Epoch 9/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.1018 - accuracy: 0.4978 - val_loss: 1.0921 - val_accuracy: 0.5394\n",
            "Epoch 10/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.0839 - accuracy: 0.5161 - val_loss: 1.0765 - val_accuracy: 0.3545\n",
            "Epoch 11/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.0657 - accuracy: 0.5369 - val_loss: 1.0595 - val_accuracy: 0.5848\n",
            "Epoch 12/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.0503 - accuracy: 0.5871 - val_loss: 1.0338 - val_accuracy: 0.6936\n",
            "Epoch 13/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.0293 - accuracy: 0.6169 - val_loss: 1.0203 - val_accuracy: 0.5340\n",
            "Epoch 14/120\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0072 - accuracy: 0.6383 - val_loss: 0.9961 - val_accuracy: 0.5240\n",
            "Epoch 15/120\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9774 - accuracy: 0.6639 - val_loss: 0.9652 - val_accuracy: 0.6963\n",
            "Epoch 16/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.9418 - accuracy: 0.6921 - val_loss: 0.9291 - val_accuracy: 0.6002\n",
            "Epoch 17/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.9017 - accuracy: 0.7024 - val_loss: 0.8829 - val_accuracy: 0.8178\n",
            "Epoch 18/120\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.8533 - accuracy: 0.7304 - val_loss: 0.8430 - val_accuracy: 0.7289\n",
            "Epoch 19/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.8055 - accuracy: 0.7486 - val_loss: 0.7899 - val_accuracy: 0.7761\n",
            "Epoch 20/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.7571 - accuracy: 0.7681 - val_loss: 0.7547 - val_accuracy: 0.7706\n",
            "Epoch 21/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.7134 - accuracy: 0.7864 - val_loss: 0.7150 - val_accuracy: 0.8187\n",
            "Epoch 22/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.8032 - val_loss: 0.6977 - val_accuracy: 0.7552\n",
            "Epoch 23/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.6364 - accuracy: 0.8142 - val_loss: 0.6529 - val_accuracy: 0.8241\n",
            "Epoch 24/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.5999 - accuracy: 0.8334 - val_loss: 0.6321 - val_accuracy: 0.7688\n",
            "Epoch 25/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.5649 - accuracy: 0.8384 - val_loss: 0.5952 - val_accuracy: 0.7978\n",
            "Epoch 26/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.5306 - accuracy: 0.8477 - val_loss: 0.5580 - val_accuracy: 0.8731\n",
            "Epoch 27/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.4976 - accuracy: 0.8557 - val_loss: 0.5310 - val_accuracy: 0.8740\n",
            "Epoch 28/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.8592 - val_loss: 0.5057 - val_accuracy: 0.8903\n",
            "Epoch 29/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.4406 - accuracy: 0.8677 - val_loss: 0.4973 - val_accuracy: 0.8749\n",
            "Epoch 30/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8713 - val_loss: 0.4699 - val_accuracy: 0.8840\n",
            "Epoch 31/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8792 - val_loss: 0.4524 - val_accuracy: 0.8649\n",
            "Epoch 32/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8822 - val_loss: 0.4312 - val_accuracy: 0.8912\n",
            "Epoch 33/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.8873 - val_loss: 0.4169 - val_accuracy: 0.8930\n",
            "Epoch 34/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8909 - val_loss: 0.4137 - val_accuracy: 0.8803\n",
            "Epoch 35/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.3236 - accuracy: 0.8947 - val_loss: 0.3961 - val_accuracy: 0.9012\n",
            "Epoch 36/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.9001 - val_loss: 0.4009 - val_accuracy: 0.8876\n",
            "Epoch 37/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2951 - accuracy: 0.9030 - val_loss: 0.3820 - val_accuracy: 0.9021\n",
            "Epoch 38/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2827 - accuracy: 0.9109 - val_loss: 0.3822 - val_accuracy: 0.8994\n",
            "Epoch 39/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2711 - accuracy: 0.9113 - val_loss: 0.3630 - val_accuracy: 0.9084\n",
            "Epoch 40/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.9168 - val_loss: 0.3547 - val_accuracy: 0.9112\n",
            "Epoch 41/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2498 - accuracy: 0.9208 - val_loss: 0.3505 - val_accuracy: 0.9121\n",
            "Epoch 42/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2394 - accuracy: 0.9245 - val_loss: 0.3505 - val_accuracy: 0.9048\n",
            "Epoch 43/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2305 - accuracy: 0.9291 - val_loss: 0.3454 - val_accuracy: 0.9130\n",
            "Epoch 44/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9320 - val_loss: 0.3506 - val_accuracy: 0.9093\n",
            "Epoch 45/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9350 - val_loss: 0.3547 - val_accuracy: 0.9102\n",
            "Epoch 46/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9355 - val_loss: 0.3273 - val_accuracy: 0.9093\n",
            "Epoch 47/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1977 - accuracy: 0.9394 - val_loss: 0.3355 - val_accuracy: 0.9093\n",
            "Epoch 48/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1907 - accuracy: 0.9395 - val_loss: 0.3298 - val_accuracy: 0.9139\n",
            "Epoch 49/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9422 - val_loss: 0.3232 - val_accuracy: 0.9066\n",
            "Epoch 50/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1772 - accuracy: 0.9456 - val_loss: 0.3234 - val_accuracy: 0.9093\n",
            "Epoch 51/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9467 - val_loss: 0.3174 - val_accuracy: 0.9066\n",
            "Epoch 52/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9488 - val_loss: 0.3352 - val_accuracy: 0.9121\n",
            "Epoch 53/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.9520 - val_loss: 0.3220 - val_accuracy: 0.9102\n",
            "Epoch 54/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9517 - val_loss: 0.3152 - val_accuracy: 0.9012\n",
            "Epoch 55/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1501 - accuracy: 0.9547 - val_loss: 0.3117 - val_accuracy: 0.9039\n",
            "Epoch 56/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9563 - val_loss: 0.3014 - val_accuracy: 0.9039\n",
            "Epoch 57/120\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.1417 - accuracy: 0.9570 - val_loss: 0.3101 - val_accuracy: 0.9084\n",
            "Epoch 58/120\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.1374 - accuracy: 0.9581 - val_loss: 0.3107 - val_accuracy: 0.9102\n",
            "Epoch 59/120\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.1333 - accuracy: 0.9594 - val_loss: 0.3025 - val_accuracy: 0.9057\n",
            "Epoch 60/120\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.1296 - accuracy: 0.9603 - val_loss: 0.3003 - val_accuracy: 0.9021\n",
            "Epoch 61/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9643 - val_loss: 0.2887 - val_accuracy: 0.9039\n",
            "Epoch 62/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9642 - val_loss: 0.2906 - val_accuracy: 0.9030\n",
            "Epoch 63/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9642 - val_loss: 0.3019 - val_accuracy: 0.9048\n",
            "Epoch 64/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9669 - val_loss: 0.2894 - val_accuracy: 0.9021\n",
            "Epoch 65/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9661 - val_loss: 0.2929 - val_accuracy: 0.9030\n",
            "Epoch 66/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9680 - val_loss: 0.3128 - val_accuracy: 0.9075\n",
            "Epoch 67/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9688 - val_loss: 0.2893 - val_accuracy: 0.9030\n",
            "Epoch 68/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9699 - val_loss: 0.2960 - val_accuracy: 0.9030\n",
            "Epoch 69/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9704 - val_loss: 0.2997 - val_accuracy: 0.9057\n",
            "Epoch 70/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9712 - val_loss: 0.2893 - val_accuracy: 0.9039\n",
            "Epoch 71/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9733 - val_loss: 0.2860 - val_accuracy: 0.9030\n",
            "Epoch 72/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9734 - val_loss: 0.2838 - val_accuracy: 0.9048\n",
            "Epoch 73/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0948 - accuracy: 0.9746 - val_loss: 0.2830 - val_accuracy: 0.9021\n",
            "Epoch 74/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0929 - accuracy: 0.9746 - val_loss: 0.2770 - val_accuracy: 0.9048\n",
            "Epoch 75/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9758 - val_loss: 0.2742 - val_accuracy: 0.9030\n",
            "Epoch 76/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.2677 - val_accuracy: 0.9012\n",
            "Epoch 77/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0874 - accuracy: 0.9763 - val_loss: 0.2800 - val_accuracy: 0.9066\n",
            "Epoch 78/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9763 - val_loss: 0.2681 - val_accuracy: 0.9021\n",
            "Epoch 79/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0843 - accuracy: 0.9765 - val_loss: 0.2678 - val_accuracy: 0.9012\n",
            "Epoch 80/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0825 - accuracy: 0.9779 - val_loss: 0.2678 - val_accuracy: 0.9039\n",
            "Epoch 81/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.2628 - val_accuracy: 0.9030\n",
            "Epoch 82/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9778 - val_loss: 0.2649 - val_accuracy: 0.9021\n",
            "Epoch 83/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0784 - accuracy: 0.9787 - val_loss: 0.2694 - val_accuracy: 0.9057\n",
            "Epoch 84/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9787 - val_loss: 0.2647 - val_accuracy: 0.9030\n",
            "Epoch 85/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9790 - val_loss: 0.2672 - val_accuracy: 0.9021\n",
            "Epoch 86/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9805 - val_loss: 0.2594 - val_accuracy: 0.9048\n",
            "Epoch 87/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0735 - accuracy: 0.9806 - val_loss: 0.2649 - val_accuracy: 0.9066\n",
            "Epoch 88/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9805 - val_loss: 0.2550 - val_accuracy: 0.9048\n",
            "Epoch 89/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9803 - val_loss: 0.2615 - val_accuracy: 0.9057\n",
            "Epoch 90/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0702 - accuracy: 0.9805 - val_loss: 0.2504 - val_accuracy: 0.9048\n",
            "Epoch 91/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9810 - val_loss: 0.2542 - val_accuracy: 0.9093\n",
            "Epoch 92/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0683 - accuracy: 0.9811 - val_loss: 0.2505 - val_accuracy: 0.9075\n",
            "Epoch 93/120\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.2545 - val_accuracy: 0.9075\n",
            "Epoch 94/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9814 - val_loss: 0.2549 - val_accuracy: 0.9075\n",
            "Epoch 95/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9814 - val_loss: 0.2558 - val_accuracy: 0.9075\n",
            "Epoch 96/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9826 - val_loss: 0.2466 - val_accuracy: 0.9093\n",
            "Epoch 97/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9818 - val_loss: 0.2543 - val_accuracy: 0.9084\n",
            "Epoch 98/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9819 - val_loss: 0.2526 - val_accuracy: 0.9093\n",
            "Epoch 99/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9834 - val_loss: 0.2562 - val_accuracy: 0.9075\n",
            "Epoch 100/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9838 - val_loss: 0.2443 - val_accuracy: 0.9084\n",
            "Epoch 101/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9829 - val_loss: 0.2565 - val_accuracy: 0.9066\n",
            "Epoch 102/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9842 - val_loss: 0.2429 - val_accuracy: 0.9084\n",
            "Epoch 103/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.9838 - val_loss: 0.2396 - val_accuracy: 0.9093\n",
            "Epoch 104/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9840 - val_loss: 0.2403 - val_accuracy: 0.9102\n",
            "Epoch 105/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9840 - val_loss: 0.2456 - val_accuracy: 0.9084\n",
            "Epoch 106/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9843 - val_loss: 0.2451 - val_accuracy: 0.9093\n",
            "Epoch 107/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9842 - val_loss: 0.2410 - val_accuracy: 0.9121\n",
            "Epoch 108/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9850 - val_loss: 0.2375 - val_accuracy: 0.9130\n",
            "Epoch 109/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9851 - val_loss: 0.2353 - val_accuracy: 0.9139\n",
            "Epoch 110/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9850 - val_loss: 0.2421 - val_accuracy: 0.9130\n",
            "Epoch 111/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9856 - val_loss: 0.2425 - val_accuracy: 0.9139\n",
            "Epoch 112/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9856 - val_loss: 0.2421 - val_accuracy: 0.9139\n",
            "Epoch 113/120\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.2377 - val_accuracy: 0.9139\n",
            "Epoch 114/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.2348 - val_accuracy: 0.9139\n",
            "Epoch 115/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9858 - val_loss: 0.2330 - val_accuracy: 0.9157\n",
            "Epoch 116/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9858 - val_loss: 0.2392 - val_accuracy: 0.9139\n",
            "Epoch 117/120\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0503 - accuracy: 0.9867 - val_loss: 0.2297 - val_accuracy: 0.9175\n",
            "Epoch 118/120\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.0500 - accuracy: 0.9862 - val_loss: 0.2295 - val_accuracy: 0.9184\n",
            "Epoch 119/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9866 - val_loss: 0.2276 - val_accuracy: 0.9175\n",
            "Epoch 120/120\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 0.2339 - val_accuracy: 0.9157\n",
            "training time =  142.32258582115173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion**"
      ],
      "metadata": {
        "id": "EpY384BISKJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use TensorFlow to implement an MLP classifier for the Kaggle dataset.\n",
        "\n",
        "Given the architecture used (3 hidden layers with 256 units), we reach an accuracy score of about 98.5% in 120 epochs. \n",
        "\n",
        "The training time is 2 minutes 22 seconds. "
      ],
      "metadata": {
        "id": "z03zhWh5SM8_"
      }
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-02-21 13:47:04,518 | connection.py:36 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-02-21 13:47:04,520 | app.py:61 | Opened (insecure) gRPC connection\n",
      "DEBUG flower 2022-02-21 13:47:04,520 | connection.py:36 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10505.71301540864\n",
      "Training finished for round 1\n",
      "10688.90352291282\n",
      "Training finished for round 2\n",
      "10149.730085754749\n",
      "Training finished for round 3\n",
      "10316.011154703214\n",
      "Training finished for round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-02-21 13:47:06,870 | connection.py:68 | Insecure gRPC channel closed\n",
      "INFO flower 2022-02-21 13:47:06,870 | app.py:72 | Disconnect and shut down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10465.763155816605\n",
      "Training finished for round 5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import utils\n",
    "\n",
    "#COMPRESSION MODELS = {'stc','dgc','sgd','none'}\n",
    "Compression_model = 'stc'\n",
    "Print_bits = True\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "def get_bits(T, compression_method, approx=False):\n",
    "    \"\"\"\n",
    "    Returns the number of bits that are required to communicate the Tensor T, which was compressed with compresion_method\n",
    "    \"\"\"\n",
    "\n",
    "    B_val = {\"none\" : 32, \"dgc\" : 32, \"stc\" : 1, \"sgd\" : 1}[compression_method]\n",
    "\n",
    "    # dense methods\n",
    "    if compression_method in [\"none\", \"sgd\"]:\n",
    "        k = T.numel()\n",
    "        B_pos = 0\n",
    "\n",
    "    # sparse methods non-optimal encoding\n",
    "    elif compression_method in [\"dgc\"]:\n",
    "        k = torch.sum(T!=0.0).item()\n",
    "        B_pos = 16\n",
    "\n",
    "    # sparse methods golomb encoding\n",
    "    elif compression_method in [\"stc\"]:\n",
    "        k = torch.sum(T!=0.0).item()\n",
    "        N = T.numel()\n",
    "\n",
    "        q = (k+1)/(N+1)\n",
    "        golden = (np.sqrt(5)+1)/2\n",
    "\n",
    "        if q == 1:\n",
    "            return B_val*T.numel()\n",
    "        if q == 0:\n",
    "            return 0\n",
    "\n",
    "        b_star = 1 + np.floor(np.log2(np.log(golden-1)/np.log(1-q)))\n",
    "\n",
    "        if approx:\n",
    "            B_pos = b_star + 1/(1-(1-q)**(2**b_star)) + 1\n",
    "        else:\n",
    "            idc = torch.nonzero(T.view(-1))\n",
    "            distances = idc[:]-torch.cat([torch.Tensor([[-1]]).long().to(\"cuda\"),idc[:-1]])\n",
    "            B_pos = torch.mean(torch.ceil(distances.float()/2**b_star)).item()+(b_star+1)\n",
    "\n",
    "    b_total = (B_pos+B_val)*k\n",
    "    f = open(\"bitsEnviados.txt\", \"a\")\n",
    "    f.write(str(b_total)+\"\\n\")\n",
    "    f.close()\n",
    "    return b_total\n",
    "\n",
    "def approx_v(T, p, frac):\n",
    "    if frac < 1.0:\n",
    "        n_elements = T.numel()\n",
    "        n_sample = min(int(max(np.ceil(n_elements * frac), np.ceil(100/p))), n_elements)\n",
    "        n_top = int(np.ceil(n_sample*p))\n",
    "\n",
    "        if n_elements == n_sample:\n",
    "            i = 0\n",
    "        else:\n",
    "            i = np.random.randint(n_elements-n_sample)\n",
    "\n",
    "        topk, _ = torch.topk(T.flatten()[i:i+n_sample], n_top)\n",
    "        if topk[-1] == 0.0 or topk[-1] == T.max():\n",
    "            return approx_v(T, p, 1.0)\n",
    "    else:\n",
    "        n_elements = T.numel()\n",
    "        n_top = int(np.ceil(n_elements*p))\n",
    "        topk, _ = torch.topk(T.flatten(), n_top)\n",
    "\n",
    "    return topk[-1], topk\n",
    "\n",
    "#STC COMPRESSION\n",
    "def STC(param, p, aprox):\n",
    "    seq = torch.as_tensor(param[0], dtype= float, device='cpu')\n",
    "    label = torch.as_tensor(param[1], dtype= float, device='cpu')\n",
    "    seq = seq.type(torch.FloatTensor)\n",
    "    label = label.type(torch.FloatTensor)\n",
    "    T = [seq,label]\n",
    "    tensor = [seq,label]\n",
    "    for x in range(len(T)):\n",
    "        T_abs = torch.abs((T[x]))\n",
    "        v, topk = approx_v(T_abs, p, aprox)\n",
    "        mean = torch.mean(topk)  \n",
    "        out_ = torch.where(T[x] >= v, mean, torch.Tensor([0.0]).to(device))\n",
    "        out = torch.where(T[x] <= -v, -mean, out_)\n",
    "        tensor[x] = out\n",
    "        T[x] = out\n",
    "        T[x] = T[x].cpu().detach().numpy()\n",
    "    if Print_bits:\n",
    "        print(get_bits(tensor[0],'stc',aprox) + get_bits(tensor[1],'stc',aprox))\n",
    "    return (T[0],T[1])\n",
    "\n",
    "#DGC COMPRESSION\n",
    "def DGC(param, p, aprox):\n",
    "    '''\n",
    "    \"Deep Gradient Compression: Reducing the communication Bandwidth for Distributed Training, Lin et al.\"\n",
    "    '''\n",
    "    if p >= 1.0:\n",
    "        return param\n",
    "    seq = torch.as_tensor(param[0], dtype= float, device='cuda')\n",
    "    label = torch.as_tensor(param[1], dtype= float, device='cuda')\n",
    "    seq = seq.type(torch.cuda.FloatTensor)\n",
    "    label = label.type(torch.cuda.FloatTensor)\n",
    "    T = [seq,label]\n",
    "    tensor = [seq,label]\n",
    "    for x in range(len(T)):\n",
    "        T_abs = torch.abs(T[x])\n",
    "        v, _ = approx_v(T_abs, p, aprox)\n",
    "        out = torch.where(T_abs >= v, T[x], torch.Tensor([0.0]).to(device))\n",
    "        tensor[x] = out\n",
    "        T[x] = out\n",
    "        T[x] = T[x].cpu().detach().numpy()\n",
    "    if Print_bits:\n",
    "        print(get_bits(tensor[0],'dgc',aprox) + get_bits(tensor[1],'dgc',aprox))\n",
    "    return (T[0],T[1])\n",
    "\n",
    "#NO COMPRESSION\n",
    "def none(param, p, aprox):\n",
    "    '''\n",
    "    Identity\n",
    "    '''\n",
    "    seq = torch.as_tensor(param[0], dtype= float, device='cuda')\n",
    "    label = torch.as_tensor(param[1], dtype= float, device='cuda')\n",
    "    seq = seq.type(torch.cuda.FloatTensor)\n",
    "    label = label.type(torch.cuda.FloatTensor)\n",
    "    tensor = (seq,label)\n",
    "    if Print_bits:\n",
    "        print(get_bits(tensor[0],'none',aprox) + get_bits(tensor[1],'none',aprox))\n",
    "    return param\n",
    "\n",
    "#SGD COMPRESSION\n",
    "def SGD(param,p,aprox):\n",
    "    \"\"\"\n",
    "    signSGD: Compressed Optimisation for non-convex Problems, Bernstein et al.\n",
    "\n",
    "    \"\"\"\n",
    "    seq = torch.as_tensor(param[0], dtype= float, device='cuda')\n",
    "    label = torch.as_tensor(param[1], dtype= float, device='cuda')\n",
    "    seq = seq.type(torch.cuda.FloatTensor)\n",
    "    label = label.type(torch.cuda.FloatTensor)\n",
    "    T = [seq,label]\n",
    "    tensor = [seq,label]\n",
    "    for x in range(len(T)):\n",
    "        T[x] = T[x].sign()\n",
    "        tensor[x] = T[x]\n",
    "        T[x] = T[x].cpu().detach().numpy()\n",
    "    if Print_bits:\n",
    "        print(get_bits(tensor[0],'sgd',aprox) + get_bits(tensor[1],'sgd',aprox))\n",
    "    return (T[0],T[1])\n",
    "\n",
    "\n",
    "# Load MNIST dataset from https://www.openml.org/d/554\n",
    "(X_train, y_train), (X_test, y_test) = utils.load_mnist()\n",
    "\n",
    "# Split train set into 10 partitions and randomly use one for training.\n",
    "partition_id = np.random.choice(10)\n",
    "(X_train, y_train) = utils.partition(X_train, y_train, 10)[partition_id]\n",
    "\n",
    "# Create LogisticRegression Model\n",
    "model = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    max_iter=1,  # local epoch\n",
    "    warm_start=True,  # prevent refreshing weights when fitting\n",
    ")\n",
    "# Setting initial parameters, akin to model.compile for keras models\n",
    "utils.set_initial_params(model)\n",
    "\n",
    "#compress param model\n",
    "class MnistClient(fl.client.NumPyClient):\n",
    "    def get_parameters(self): # type: ignore\n",
    "        return utils.get_model_parameters(model)\n",
    "    \n",
    "    def fit(self, parameters, config): # type: ignore\n",
    "        utils.set_model_params(model, parameters)\n",
    "        # Ignore convergence failure due to low local epochs\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            model.fit(X_train, y_train)\n",
    "            #-------------------------TRANSFORM----------------\n",
    "            if Compression_model == 'stc':\n",
    "                T = STC(utils.get_model_parameters(model),0.25,0.8)\n",
    "            elif Compression_model == 'dgc':\n",
    "                T = DGC(utils.get_model_parameters(model),0.25,0.8)\n",
    "            elif Compression_model == 'sgd':\n",
    "                T = SGD(utils.get_model_parameters(model),0.25,0.8)\n",
    "            elif Compression_model == 'none':\n",
    "                T = none(utils.get_model_parameters(model),0.25,0.8)\n",
    "                \n",
    "            utils.set_model_params(model, T)    \n",
    "        \n",
    "        print(f\"Training finished for round {config['rnd']}\")\n",
    "        return utils.get_model_parameters(model), len(X_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config): # type: ignore\n",
    "        utils.set_model_params(model, parameters)\n",
    "        loss = log_loss(y_test, model.predict_proba(X_test))\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        return loss, len(X_test), {\"accuracy\": accuracy}\n",
    "    \n",
    "fl.client.start_numpy_client(\"localhost:8080\", client=MnistClient())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
